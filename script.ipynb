{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data and view \n",
    "\n",
    "data = pd.read_csv(\"/Users/victoriaguo/Desktop/DS 4002/project 1/original_data.csv\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for NAs\n",
    "\n",
    "data.isnull().sum()\n",
    "\n",
    "# fill review text NA values as \"missing\" instead of empty\n",
    "data['reviewText']=data['reviewText'].fillna('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine review text and summary columns\n",
    "data['reviews']=data['reviewText']+data['summary']\n",
    "data=data.drop(['reviewText', 'summary'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sentiment column\n",
    "data['overall'].value_counts()\n",
    "\n",
    "def f(row):    \n",
    "    if row['overall'] == 3.0:\n",
    "        val = 'Neutral'\n",
    "    elif row['overall'] == 1.0 or row['overall'] == 2.0:\n",
    "        val = 'Negative'\n",
    "    elif row['overall'] == 4.0 or row['overall'] == 5.0:\n",
    "        val = 'Positive'\n",
    "    else:\n",
    "        val = -1\n",
    "    return val\n",
    "\n",
    "data['sentiment'] = data.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view our data with the added column \n",
    "data.head()\n",
    "\n",
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop reviewierID, unixReviewTime, asin columns\n",
    "\n",
    "data=data.drop(['asin'], axis=1)\n",
    "data=data.drop(['reviewerID'], axis=1)\n",
    "data=data.drop(['reviewerName'], axis=1)\n",
    "data=data.drop(['unixReviewTime'], axis=1)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change reviewTime column to date year format \n",
    "date_new = data[\"reviewTime\"].str.split(\",\", n = 1, expand = True) \n",
    "\n",
    "data[\"date\"]= date_new[0] \n",
    "data[\"year\"]= date_new[1]\n",
    "\n",
    "data[\"year\"]= date_new[1] \n",
    "\n",
    "data=data.drop(['reviewTime'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at our cleaned dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column with helpfulness rate of a review \n",
    "new1 = data[\"helpful\"].str.split(\",\", n = 1, expand = True)\n",
    "new2 = new1[0].str.split(\"[\", n = 1, expand = True)\n",
    "new3 = new1[1].str.split(\"]\", n = 1, expand = True)\n",
    "\n",
    "#Resetting the index\n",
    "new2.reset_index(drop=True, inplace=True)\n",
    "new3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Dropping empty columns due to splitting \n",
    "new2=new2.drop([0], axis=1)\n",
    "new3=new3.drop([1], axis=1)\n",
    "\n",
    "#Concatenating the splitted columns\n",
    "helpful=pd.concat([new2, new3], axis=1)\n",
    "\n",
    "def trim_all_columns(df):\n",
    "    \"\"\"\n",
    "    Trim whitespace from ends of each value across all series in dataframe\n",
    "    \"\"\"\n",
    "    trim_strings = lambda x: x.strip() if isinstance(x, str) else x\n",
    "    return df.applymap(trim_strings)\n",
    "\n",
    "#Applying the function\n",
    "helpful= trim_all_columns(helpful)\n",
    "\n",
    "#Converting into integer types\n",
    "helpful[0]=helpful[0].astype(str).astype(int)\n",
    "helpful[1]=helpful[1].astype(str).astype(int)\n",
    "\n",
    "#Dividing the two columns, we have 0 in the second columns when dvided gives error, so I'm ignoring those errors\n",
    "try:\n",
    "  helpful['result'] = helpful[1]/helpful[0]\n",
    "except ZeroDivisionError:\n",
    "  helpful['result']=0\n",
    "\n",
    "#Filling the NaN values(created due to dividing) with 0\n",
    "helpful['result'] = helpful['result'].fillna(0)\n",
    "\n",
    "#Rounding of the results to two decimal places\n",
    "helpful['result']=helpful['result'].round(2) \n",
    "\n",
    "#Attaching the results to a new column of the main dataframe\n",
    "data['helpful_rate']=helpful['result']\n",
    "\n",
    "#dropping the helpful column from main dataframe\n",
    "data=data.drop(['helpful'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop date column and keep year\n",
    "data=data.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at dataset \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the review column \n",
    "def review_cleaning(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to review column in data\n",
    "data['reviews']=data['reviews'].apply(lambda x:review_cleaning(x))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the neutral reviews (only comparing positive and negative)\n",
    "\n",
    "indexSentiment = data[(data['sentiment'] == 'Neutral')].index\n",
    "data.drop(indexSentiment, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data to csv\n",
    "\n",
    "data.to_csv(\"/Users/victoriaguo/Desktop/DS 4002/project 1/final_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from plotly import tools\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/victoriaguo/Desktop/DS 4002/project 1/final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate table of sentiment vs. helpfulness \n",
    "\n",
    "pd.DataFrame(data.groupby('sentiment')['helpful_rate'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create boxplot that shows sentiment and helpfulness\n",
    "\n",
    "sns.boxplot( x=data[\"sentiment\"], y=data[\"helpful_rate\"])\n",
    "plt.title('Sentiment vs Helpfulness')\n",
    "plt.xlabel('Sentiment categories')\n",
    "plt.ylabel('Helpful Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create violin plot because it's hard to tell with boxplot\n",
    "\n",
    "sns.violinplot( x=data[\"sentiment\"], y=data[\"helpful_rate\"])\n",
    "plt.title('Sentiment vs Helpfulness')\n",
    "plt.xlabel('Sentiment categories')\n",
    "plt.ylabel('Helpful Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 0 values in helpful rate column \n",
    "\n",
    "data = data[data['helpful_rate'] != 0.00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new violin plot with removed observations\n",
    "sns.violinplot( x=data[\"sentiment\"], y=data[\"helpful_rate\"])\n",
    "plt.title('Sentiment vs Helpfulness')\n",
    "plt.xlabel('Sentiment categories')\n",
    "plt.ylabel('Helpful Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new table with removed 0 values \n",
    "\n",
    "pd.DataFrame(data.groupby('sentiment')['helpful_rate'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pie chart \n",
    "\n",
    "category_counts = data['sentiment'].value_counts()\n",
    "\n",
    "# Create the pie chart\n",
    "plt.pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%')\n",
    "plt.title('Sentiment Pie Chart')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning for bigram plot\n",
    "stop_words= ['yourselves', 'between', 'whom', 'itself', 'is', \"she's\", 'up', 'herself', 'here', 'your', 'each', \n",
    "             'we', 'he', 'my', \"you've\", 'having', 'in', 'both', 'for', 'themselves', 'are', 'them', 'other',\n",
    "             'and', 'an', 'during', 'their', 'can', 'yourself', 'she', 'until', 'so', 'these', 'ours', 'above', \n",
    "             'what', 'while', 'have', 're', 'more', 'only', \"needn't\", 'when', 'just', 'that', 'were', \"don't\", \n",
    "             'very', 'should', 'any', 'y', 'isn', 'who',  'a', 'they', 'to', 'too', \"should've\", 'has', 'before',\n",
    "             'into', 'yours', \"it's\", 'do', 'against', 'on',  'now', 'her', 've', 'd', 'by', 'am', 'from', \n",
    "             'about', 'further', \"that'll\", \"you'd\", 'you', 'as', 'how', 'been', 'the', 'or', 'doing', 'such',\n",
    "             'his', 'himself', 'ourselves',  'was', 'through', 'out', 'below', 'own', 'myself', 'theirs', \n",
    "             'me', 'why', 'once',  'him', 'than', 'be', 'most', \"you'll\", 'same', 'some', 'with', 'few', 'it',\n",
    "             'at', 'after', 'its', 'which', 'there','our', 'this', 'hers', 'being', 'did', 'of', 'had', 'under',\n",
    "             'over','again', 'where', 'those', 'then', \"you're\", 'i', 'because', 'does', 'all']\n",
    "\n",
    "\n",
    "data['reviews'] = data['reviews'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigram plots \n",
    "positive_reviews = data[data[\"sentiment\"]=='Positive'].dropna()\n",
    "negative_reviews = data[data[\"sentiment\"]=='Negative'].dropna()\n",
    "\n",
    "def generate_ngrams(text, n_gram=1):\n",
    "    token = [token for token in text.lower().split(\" \") if token != \"\"]\n",
    "    ngrams = zip(*[token[i:] for i in range(n_gram)])\n",
    "    return [\" \".join(ngram) for ngram in ngrams]\n",
    "\n",
    "def horizontal_bar_chart(data, color):\n",
    "    trace = go.Bar(\n",
    "        y=data[\"word\"].values[::-1],\n",
    "        x=data[\"wordcount\"].values[::-1],\n",
    "        showlegend=False,\n",
    "        orientation = 'h',\n",
    "        marker=dict(\n",
    "            color=color,\n",
    "        ),\n",
    "    )\n",
    "    return trace\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "## Get the bar chart from positive reviews ##\n",
    "freq_dict = defaultdict(int)\n",
    "for sent in positive_reviews[\"reviews\"]:\n",
    "    for word in generate_ngrams(sent,2):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace_pos = horizontal_bar_chart(fd_sorted.head(20), 'green')\n",
    "\n",
    "\n",
    "\n",
    "## Get the bar chart from negative reviews ##\n",
    "freq_dict = defaultdict(int)\n",
    "for sent in negative_reviews[\"reviews\"]:\n",
    "    for word in generate_ngrams(sent,2):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace_neg = horizontal_bar_chart(fd_sorted.head(20), 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out two bar charts\n",
    "\n",
    "plot = tools.make_subplots(rows=2, cols=1, vertical_spacing=0.1, subplot_titles=[\"Positive Review Words\", \"Negative Review Words\"])\n",
    "plot.append_trace(trace_pos, 1, 1)\n",
    "plot.append_trace(trace_neg, 2, 1)\n",
    "\n",
    "plot['layout'].update(height=1200, width=900, paper_bgcolor='rgb(255, 255, 255)', title=\"Bigram Plots\")\n",
    "\n",
    "iplot(plot, filename='bigram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data \n",
    "data = pd.read_csv(\"/Users/victoriaguo/Desktop/DS 4002/project 1/final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into two groups: positive and negative\n",
    "positive = data[data['sentiment'] == 'Positive']['helpful_rate']\n",
    "negative = data[data['sentiment'] == 'Negative']['helpful_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for normality: kolmogorov-smirnov test\n",
    "from scipy.stats import kstest\n",
    "\n",
    "statistic, p_value = kstest(data['helpful_rate'], 'norm')\n",
    "\n",
    "print(\"Kolmogorov-Smirnov Test:\")\n",
    "print(\"Statistic:\", statistic)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for constant variance: bartlett's \n",
    "from scipy.stats import bartlett\n",
    "\n",
    "statistic, p_value = bartlett(positive, negative)\n",
    "print(\"Bartlett's Test:\")\n",
    "print(\"Statistic:\", statistic)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform independent t tests\n",
    "t_statistic, p_value = ttest_ind(positive, negative)\n",
    "\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-Value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe with sentiment as columns\n",
    "\n",
    "new = pd.DataFrame()\n",
    "\n",
    "new['Positive'] = data.loc[data['sentiment'] == 'Positive', 'helpful_rate'].reset_index(drop=True)\n",
    "\n",
    "new['Negative'] = data.loc[data['sentiment'] == 'Negative', 'helpful_rate'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 0 values\n",
    "new = new[new['Positive'] != 0.00]\n",
    "new = new[new['Negative'] != 0.00]\n",
    "\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because the assumptions above were not met, we performed a non-parametric test to validate the conclusions (no assumptions about data necessary)\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Assuming 'data' is your paired data\n",
    "# Perform Wilcoxon signed-rank test\n",
    "statistic, p_value = wilcoxon(new)\n",
    "print(\"Wilcoxon Signed-Rank Test:\")\n",
    "print(\"Statistic:\", statistic)\n",
    "print(\"P-value:\", p_value)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
